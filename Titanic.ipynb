{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Titanic.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOphiiObeWnN4R7OgyDgkvR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aviad-Hedvat/ML---Titanic/blob/main/Titanic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports\n",
        "First of all I am going to import all relevant libraries that I'm foing to use while the assignment but, there may be more imports later."
      ],
      "metadata": {
        "id": "CHZaChbHIHcN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0OeBOzCoGx32"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# define plt & sns settings\n",
        "sns.set_theme()\n",
        "plt.rcParams[\"font.size\"] = 20\n",
        "plt.rcParams[\"axes.labelsize\"] = 20\n",
        "plt.rcParams[\"xtick.labelsize\"] = 20\n",
        "plt.rcParams[\"ytick.labelsize\"] = 20\n",
        "plt.rcParams[\"legend.fontsize\"] = 20\n",
        "plt.rcParams[\"legend.markerscale\"] = 1.5\n",
        "plt.rcParams[\"figure.figsize\"] = (20, 10)\n",
        "plt.rcParams[\"legend.title_fontsize\"] = 20"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_train = pd.read_csv(r'./train.csv')\n",
        "titanic_train.replace('', np.NaN, inplace=True)\n",
        "titanic_train.fillna(np.NaN, inplace=True)"
      ],
      "metadata": {
        "id": "fgsbXEnwG0_0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_age = round(titanic_train['Age'].dropna().mean()) #mean age of existed ages in the data\n",
        "titanic_train['Age'].fillna(mean_age, inplace=True)\n",
        "df_not_null = titanic_train[~titanic_train['Embarked'].isnull()]\n",
        "options = np.random.choice(df_not_null['Embarked']) #get random value of all possibles values in Embarked feature\n",
        "titanic_train['Embarked'] = titanic_train['Embarked'].apply( \\\n",
        "lambda x: options if pd.isnull(x) else x)"
      ],
      "metadata": {
        "id": "Dws7tmwIHDSt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binary_cabin = [1 if str(x) != 'nan' else 0 for x in titanic_train['Cabin'].tolist()]\n",
        "titanic_train.replace(titanic_train['Cabin'].tolist(), binary_cabin, inplace=True)\n",
        "relatives = [x+y for x,y in zip(titanic_train['SibSp'], titanic_train['Parch'])]\n",
        "titanic_train['Relatives'] = relatives\n",
        "relatives_chance = titanic_train[['Relatives', 'Survived']].groupby(['Relatives'], as_index=False).mean()"
      ],
      "metadata": {
        "id": "axNa_KzoHH6-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the name titles\n",
        "titles = titanic_train['Name'].str.extract(' ([a-zA-Z]+)\\.')\n",
        "titanic_train['Title'] = titles\n",
        "# The following titles only appear a short amount so lets just merge them into one category\n",
        "titanic_train['Title'] = titanic_train['Title'].replace(['Capt', 'Col', 'Dr', 'Lady', 'Rev', 'Dona', \\\n",
        "'Mme', 'Countess', 'Don', 'Major', 'Sir', 'Jonkheer', 'Mlle'], 'Other')\n",
        "titanic_train['Title'] = titanic_train['Title'].replace('Ms', 'Miss')\n",
        "# 'Ms title only appears a few times and she always survives so i'm just gonna merge it with Miss - same meaning anyway\n",
        "# Show a table of the mean of people who survived by title.\n",
        "rate = titanic_train[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()\n",
        "titanic_train.replace(dict([(x,y) for x,y in zip(rate['Title'], rate['Survived'])]), inplace=True)\n",
        "# replace the titles with the acording survival mean from the table we got above!"
      ],
      "metadata": {
        "id": "kRlWrjTXHXT6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler #for data standartization - for Age and Fare\n",
        "\n",
        "embarked_chance = titanic_train[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean()\n",
        "new_sex = [1 if x=='female' else 0 for x in titanic_train['Sex']] \n",
        "titanic_train.replace(titanic_train['Sex'].tolist(), new_sex, inplace=True)\n",
        "titanic_train.replace(dict([(x,y) for x,y in \\\n",
        "zip(embarked_chance['Embarked'], embarked_chance['Survived'])]), inplace=True)\n",
        "\n",
        "mm_scaler = MinMaxScaler()\n",
        "age_fare = mm_scaler.fit_transform(titanic_train[['Age', 'Fare']])\n",
        "titanic_train['Age'] = age_fare.copy()\n",
        "titanic_train['Fare'] = age_fare.copy()\n",
        "\n",
        "fpc = [(x/y) + z for x,y,z in zip(titanic_train['Fare'], titanic_train['Pclass'], titanic_train['Cabin'])]\n",
        "titanic_train['FPC'] = fpc\n",
        "lonely = [1 if x==0 else 0 for x in titanic_train['Relatives']]\n",
        "titanic_train['Lonely'] = lonely\n",
        "titanic_train.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "PiJxrdUeHYTY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import model_selection\n",
        "t = titanic_train['Survived'].copy()\n",
        "titanic_train.drop('Survived', axis=1, inplace=True)\n",
        "x_train, x_val, y_train, y_val = model_selection.train_test_split(titanic_train, t, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "A8QPS3oCHZtW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import neural_network, linear_model\n",
        "\n",
        "lr_model = linear_model.LogisticRegression().fit(x_train, y_train)\n",
        "sgd_model = neural_network.MLPClassifier(activation='logistic', solver='sgd', alpha=0, max_iter=50000)\\\n",
        ".fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "0N3UPd-OHjEp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = linear_model.LogisticRegression().fit(titanic_train, t)"
      ],
      "metadata": {
        "id": "X3gOxhipHkk1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(df: pd.DataFrame):\n",
        "    df.replace('', np.NaN, inplace=True)\n",
        "    df.fillna(np.NaN, inplace=True)\n",
        "    binary_cabin = [1 if str(x) != 'nan' else 0 for x in df['Cabin'].tolist()]\n",
        "    df.replace(df['Cabin'].tolist(), binary_cabin, inplace=True)\n",
        "    relatives = [x+y for x,y in zip(df['SibSp'], df['Parch'])]\n",
        "    df['Relatives'] = relatives\n",
        "    titles = df['Name'].str.extract(' ([a-zA-Z]+)\\.')\n",
        "    df['Title'] = titles\n",
        "    df['Title'] = df['Title'].replace(['Capt', 'Col', 'Dr', 'Lady', 'Rev', 'Dona', \\\n",
        "    'Mme', 'Countess', 'Don', 'Major', 'Sir', 'Jonkheer', 'Mlle'], 'Other')\n",
        "    df['Title'] = df['Title'].replace('Ms', 'Miss')\n",
        "    df.replace(dict([(x,y) for x,y in zip(rate['Title'], rate['Survived'])]), inplace=True)\n",
        "    new_sex = [1 if x=='female' else 0 for x in df['Sex']]\n",
        "    df.replace(df['Sex'].tolist(), new_sex, inplace=True)\n",
        "    df.replace(dict([(x,y) for x,y in zip(embarked_chance['Embarked'], embarked_chance['Survived'])]), inplace=True)\n",
        "\n",
        "    age_fare = mm_scaler.fit_transform(df[['Age', 'Fare']])\n",
        "    df['Age'] = age_fare.copy()\n",
        "    df['Fare'] = age_fare.copy()\n",
        "\n",
        "    fpc = [(x/y) + z for x,y,z in zip(df['Fare'], df['Pclass'], df['Cabin'])]\n",
        "    df['FPC'] = fpc\n",
        "    lonely = [1 if x==0 else 0 for x in df['Relatives']]\n",
        "    df['Lonely'] = lonely\n",
        "    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "JXozKic5Hnyz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_csv(r'./test.csv')\n",
        "#Fare is missing so I just add a mean, everything else as I did before for age and cabin\n",
        "mean_age = round(test_data['Age'].dropna().mean())\n",
        "test_data['Age'].fillna(mean_age, inplace=True)\n",
        "fare_mean = round(test_data['Fare'].dropna().mean())\n",
        "test_data['Fare'].fillna(fare_mean, inplace=True)\n",
        "\n",
        "# now I can pass it safely to the function we created and it will handle it propertly.\n",
        "prepare_data(test_data)"
      ],
      "metadata": {
        "id": "jmk6aatYHqi7"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = pd.read_csv(r'./test.csv')\n",
        "prediction['Survived'] = model.predict(test_data)\n",
        "prediction = prediction[['PassengerId', 'Survived']]\n",
        "prediction.to_csv(r'./submission.csv', index=False)"
      ],
      "metadata": {
        "id": "p3sGuxxdHthK"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}